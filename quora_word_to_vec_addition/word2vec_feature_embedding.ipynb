{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "a = pd.read_csv('E:/Dropbox/Kaggle_competitions/Quora competition/train.csv',delimiter = ',')\n",
    "a = a.dropna()\n",
    "q1 = a['question1'].values\n",
    "q2 = a['question2'].values\n",
    "labels = a['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_embeddings = np.load(\"final_embeddings.npy\")\n",
    "dictionary = np.load('dictionary.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.12367421244261517\n",
      "0.24734842488523034\n",
      "0.3710226373278455\n",
      "0.4946968497704607\n",
      "0.6183710622130758\n",
      "0.742045274655691\n",
      "0.8657194870983062\n",
      "0.9893936995409214\n",
      "0.0\n",
      "0.12367421244261517\n",
      "0.24734842488523034\n",
      "0.3710226373278455\n",
      "0.4946968497704607\n",
      "0.6183710622130758\n",
      "0.742045274655691\n",
      "0.8657194870983062\n",
      "0.9893936995409214\n"
     ]
    }
   ],
   "source": [
    "def get_word(word):\n",
    "    if word not in dictionary:\n",
    "        return 'UNK'\n",
    "    else:\n",
    "        return word\n",
    "specialstr = '?:!/;\\|~`%1234567890.,%&$()_{}[]^\"'   \n",
    "#checki if words are in dictionary first\n",
    "question1_data = []\n",
    "question2_data = []\n",
    "count = 0\n",
    "for j in range(len(q1)):\n",
    "    if j%50000==0:\n",
    "        print(j/(len(q1)))\n",
    "    auto_data = []\n",
    "    line = q1[j]    \n",
    "    temp_words = ''.join( c for c in line if  c not in specialstr ).split()\n",
    "    #adding the leaves\n",
    "    #print(count)\n",
    "    for i in temp_words:\n",
    "        auto_data.append(final_embeddings[dictionary[get_word(i.lower())]])\n",
    "    auto_data = np.array(auto_data)\n",
    "    question1_data.append(auto_data)\n",
    "    count+=1\n",
    "    \n",
    "question1_data =  np.array(question1_data)\n",
    "\n",
    "for j in range(len(q2)):\n",
    "    if j%50000==0:\n",
    "        print(j/(len(q1)))\n",
    "    auto_data = []\n",
    "    line = q2[j]    \n",
    "    temp_words = ''.join( c for c in line if  c not in specialstr ).split()\n",
    "    #adding the leaves\n",
    "    for i in temp_words:\n",
    "        auto_data.append(final_embeddings[dictionary[get_word(i.lower())]])\n",
    "    #parent_q2.append([auto_data,j])\n",
    "    auto_data = np.array(auto_data)\n",
    "    question2_data.append(auto_data)\n",
    "    \n",
    "question2_data =  np.array(question2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "for i in range(len(question1_data)):\n",
    "    if question1_data[i].shape[0]==0 or question2_data[i].shape[0]==0 or question1_data[i].shape[0]==1 or question2_data[i].shape[0]==1 or question1_data[i].shape[0]==2 or question2_data[i].shape[0]==2:\n",
    "        pos.append(i)\n",
    "    question1_data[i] = np.round(question1_data[i],4)\n",
    "    question2_data[i] = np.round(question2_data[i],4)\n",
    "labels = np.delete(labels,pos)\n",
    "question1_data = np.delete(question1_data,pos)\n",
    "question2_data = np.delete(question2_data,pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths1 = [i.shape[0] for i in question1_data]\n",
    "lengths12 = [i.shape[0] for i in question2_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0706    ,  0.16249999, -0.0102    , ...,  0.0314    ,\n",
       "        -0.0854    ,  0.16869999],\n",
       "       [ 0.0629    ,  0.13339999,  0.0711    , ...,  0.0483    ,\n",
       "        -0.17649999,  0.1046    ],\n",
       "       [ 0.0856    ,  0.1294    ,  0.0661    , ...,  0.0777    ,\n",
       "        -0.1185    ,  0.12970001],\n",
       "       ..., \n",
       "       [-0.022     ,  0.1628    , -0.0369    , ..., -0.0486    ,\n",
       "         0.0467    ,  0.1074    ],\n",
       "       [ 0.0975    ,  0.0038    , -0.0192    , ..., -0.0073    ,\n",
       "        -0.1776    ,  0.0506    ],\n",
       "       [ 0.1098    ,  0.0441    ,  0.0139    , ..., -0.0405    ,\n",
       "        -0.0553    ,  0.0915    ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question1_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404017,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_f = np.ones((len(question1_data),3,128),np.float32)\n",
    "q1_f_cos =np.ones((len(question1_data),3,128),np.float32) \n",
    "q1_f_plane = np.ones((len(question1_data),5,128),np.float32)\n",
    "for i in range(question1_data.shape[0]):\n",
    "    f1 = np.sum(question1_data[i],0)\n",
    "    f2 = np.sum(question1_data[i][:-1],0)\n",
    "    f3 = question1_data[i][-1]\n",
    "    f4 = np.sum(question1_data[i][1:],0)\n",
    "    f5 = question1_data[i][0]\n",
    "    q1_f[i] = [f1,f2,f3]\n",
    "    q1_f_cos[i] = [f1-f2,f2-f3,f3-f1]\n",
    "    q1_f_plane[i] = [f1,f2,f3,f4,f5]\n",
    "\n",
    "q2_f = np.ones((len(question2_data),3,128),np.float32)\n",
    "q2_f_cos =np.ones((len(question1_data),3,128),np.float32)\n",
    "q2_f_plane = np.ones((len(question1_data),5,128),np.float32)\n",
    "for i in range(question1_data.shape[0]):\n",
    "    f1 = np.sum(question2_data[i],0)\n",
    "    f2 = np.sum(question2_data[i][:-1],0)\n",
    "    f3 = question2_data[i][-1]\n",
    "    f4 = np.sum(question2_data[i][1:],0)\n",
    "    f5 = question2_data[i][0]\n",
    "    q2_f[i] = [f1,f2,f3]\n",
    "    q2_f_cos[i] = [f1-f2,f2-f3,f3-f1]\n",
    "    q2_f_plane[i] = [f1,f2,f3,f4,f5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "dist = np.ones((len(q1_f),25),np.float32)\n",
    "dist_cos = np.ones((len(q1_f),9),np.float32)\n",
    "for i in range(len(q1_f_plane)):\n",
    "    dist[i] = sklearn.metrics.pairwise.pairwise_distances(q1_f_plane[i],q2_f_plane[i]).reshape(25)\n",
    "    dist_cos[i] = sklearn.metrics.pairwise.cosine_distances(q1_f_cos[i],q2_f_cos[i]).reshape(9)\n",
    "feature_mat = np.hstack((dist,dist_cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270691,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_id': 0, '_save_checkpoints_secs': 600, '_is_chief': True, '_num_worker_replicas': 0, '_model_dir': None, '_evaluation_master': '', '_save_summary_steps': 100, '_environment': 'local', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000022A07345A90>, '_tf_random_seed': None, '_master': '', '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_task_type': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\AKHILE~1\\AppData\\Local\\Temp\\tmpbnls2qt9\n",
      "WARNING:tensorflow:From C:\\Users\\akhileshsk\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\AKHILE~1\\AppData\\Local\\Temp\\tmpbnls2qt9\\model.ckpt.\n",
      "INFO:tensorflow:loss = 11.2031, step = 1\n",
      "INFO:tensorflow:global_step/sec: 422.603\n",
      "INFO:tensorflow:loss = 0.212137, step = 101 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.336\n",
      "INFO:tensorflow:loss = 0.276737, step = 201 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.88\n",
      "INFO:tensorflow:loss = 0.241902, step = 301 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.44\n",
      "INFO:tensorflow:loss = 0.348742, step = 401 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.394\n",
      "INFO:tensorflow:loss = 0.266912, step = 501 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.338\n",
      "INFO:tensorflow:loss = 0.196541, step = 601 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.732\n",
      "INFO:tensorflow:loss = 0.250131, step = 701 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.047\n",
      "INFO:tensorflow:loss = 0.206167, step = 801 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.495\n",
      "INFO:tensorflow:loss = 0.192105, step = 901 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.89\n",
      "INFO:tensorflow:loss = 0.269713, step = 1001 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.239\n",
      "INFO:tensorflow:loss = 0.220854, step = 1101 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.673\n",
      "INFO:tensorflow:loss = 0.217638, step = 1201 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.444\n",
      "INFO:tensorflow:loss = 0.20295, step = 1301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.809\n",
      "INFO:tensorflow:loss = 0.27538, step = 1401 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.893\n",
      "INFO:tensorflow:loss = 0.244564, step = 1501 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.145\n",
      "INFO:tensorflow:loss = 0.264852, step = 1601 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.521\n",
      "INFO:tensorflow:loss = 0.294595, step = 1701 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.925\n",
      "INFO:tensorflow:loss = 0.206434, step = 1801 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.674\n",
      "INFO:tensorflow:loss = 0.203989, step = 1901 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.673\n",
      "INFO:tensorflow:loss = 0.2358, step = 2001 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.925\n",
      "INFO:tensorflow:loss = 0.240136, step = 2101 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.924\n",
      "INFO:tensorflow:loss = 0.241448, step = 2201 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.444\n",
      "INFO:tensorflow:loss = 0.22964, step = 2301 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.198\n",
      "INFO:tensorflow:loss = 0.245649, step = 2401 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.235\n",
      "INFO:tensorflow:loss = 0.227019, step = 2501 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.925\n",
      "INFO:tensorflow:loss = 0.238399, step = 2601 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.236\n",
      "INFO:tensorflow:loss = 0.25571, step = 2701 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.508\n",
      "INFO:tensorflow:loss = 0.254467, step = 2801 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.675\n",
      "INFO:tensorflow:loss = 0.228556, step = 2901 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.674\n",
      "INFO:tensorflow:loss = 0.241168, step = 3001 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.508\n",
      "INFO:tensorflow:loss = 0.241356, step = 3101 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.733\n",
      "INFO:tensorflow:loss = 0.235051, step = 3201 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.179\n",
      "INFO:tensorflow:loss = 0.197866, step = 3301 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.147\n",
      "INFO:tensorflow:loss = 0.226872, step = 3401 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.047\n",
      "INFO:tensorflow:loss = 0.211606, step = 3501 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.731\n",
      "INFO:tensorflow:loss = 0.240271, step = 3601 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.199\n",
      "INFO:tensorflow:loss = 0.241938, step = 3701 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.808\n",
      "INFO:tensorflow:loss = 0.225797, step = 3801 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.048\n",
      "INFO:tensorflow:loss = 0.252198, step = 3901 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.508\n",
      "INFO:tensorflow:loss = 0.234766, step = 4001 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.303\n",
      "INFO:tensorflow:loss = 0.252434, step = 4101 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.671\n",
      "INFO:tensorflow:loss = 0.230668, step = 4201 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.733\n",
      "INFO:tensorflow:loss = 0.220847, step = 4301 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.808\n",
      "INFO:tensorflow:loss = 0.22979, step = 4401 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.147\n",
      "INFO:tensorflow:loss = 0.246938, step = 4501 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.234\n",
      "INFO:tensorflow:loss = 0.219788, step = 4601 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.197\n",
      "INFO:tensorflow:loss = 0.218888, step = 4701 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.493\n",
      "INFO:tensorflow:loss = 0.19419, step = 4801 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.508\n",
      "INFO:tensorflow:loss = 0.205629, step = 4901 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.358\n",
      "INFO:tensorflow:loss = 0.237074, step = 5001 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.234\n",
      "INFO:tensorflow:loss = 0.225154, step = 5101 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.049\n",
      "INFO:tensorflow:loss = 0.241294, step = 5201 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.19\n",
      "INFO:tensorflow:loss = 0.246318, step = 5301 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.807\n",
      "INFO:tensorflow:loss = 0.223147, step = 5401 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.491\n",
      "INFO:tensorflow:loss = 0.230025, step = 5501 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.926\n",
      "INFO:tensorflow:loss = 0.225062, step = 5601 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.236\n",
      "INFO:tensorflow:loss = 0.24144, step = 5701 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.443\n",
      "INFO:tensorflow:loss = 0.271635, step = 5801 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.88\n",
      "INFO:tensorflow:loss = 0.225801, step = 5901 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.044\n",
      "INFO:tensorflow:loss = 0.230919, step = 6001 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.496\n",
      "INFO:tensorflow:loss = 0.212759, step = 6101 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.893\n",
      "INFO:tensorflow:loss = 0.235943, step = 6201 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.893\n",
      "INFO:tensorflow:loss = 0.203787, step = 6301 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.925\n",
      "INFO:tensorflow:loss = 0.206493, step = 6401 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.443\n",
      "INFO:tensorflow:loss = 0.25339, step = 6501 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.926\n",
      "INFO:tensorflow:loss = 0.240613, step = 6601 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.674\n",
      "INFO:tensorflow:loss = 0.193446, step = 6701 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.673\n",
      "INFO:tensorflow:loss = 0.225735, step = 6801 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.925\n",
      "INFO:tensorflow:loss = 0.240766, step = 6901 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.444\n",
      "INFO:tensorflow:loss = 0.235575, step = 7001 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.605\n",
      "INFO:tensorflow:loss = 0.250953, step = 7101 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.492\n",
      "INFO:tensorflow:loss = 0.210634, step = 7201 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.892\n",
      "INFO:tensorflow:loss = 0.195172, step = 7301 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.894\n",
      "INFO:tensorflow:loss = 0.251469, step = 7401 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.301\n",
      "INFO:tensorflow:loss = 0.233913, step = 7501 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.301\n",
      "INFO:tensorflow:loss = 0.235781, step = 7601 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.893\n",
      "INFO:tensorflow:loss = 0.24015, step = 7701 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.673\n",
      "INFO:tensorflow:loss = 0.208794, step = 7801 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.605\n",
      "INFO:tensorflow:loss = 0.257031, step = 7901 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.337\n",
      "INFO:tensorflow:loss = 0.25515, step = 8001 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.253\n",
      "INFO:tensorflow:loss = 0.203805, step = 8101 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.254\n",
      "INFO:tensorflow:loss = 0.263916, step = 8201 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.443\n",
      "INFO:tensorflow:loss = 0.23115, step = 8301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.407\n",
      "INFO:tensorflow:loss = 0.236909, step = 8401 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.497\n",
      "INFO:tensorflow:loss = 0.245349, step = 8501 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.048\n",
      "INFO:tensorflow:loss = 0.291173, step = 8601 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.407\n",
      "INFO:tensorflow:loss = 0.235897, step = 8701 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.497\n",
      "INFO:tensorflow:loss = 0.202597, step = 8801 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.432\n",
      "INFO:tensorflow:loss = 0.230881, step = 8901 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.73\n",
      "INFO:tensorflow:loss = 0.223397, step = 9001 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.675\n",
      "INFO:tensorflow:loss = 0.228678, step = 9101 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.357\n",
      "INFO:tensorflow:loss = 0.245887, step = 9201 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.628\n",
      "INFO:tensorflow:loss = 0.262901, step = 9301 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.734\n",
      "INFO:tensorflow:loss = 0.262972, step = 9401 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.893\n",
      "INFO:tensorflow:loss = 0.237316, step = 9501 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.301\n",
      "INFO:tensorflow:loss = 0.209306, step = 9601 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.894\n",
      "INFO:tensorflow:loss = 0.214985, step = 9701 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.49\n",
      "INFO:tensorflow:loss = 0.203131, step = 9801 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.08\n",
      "INFO:tensorflow:loss = 0.19313, step = 9901 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.252\n",
      "INFO:tensorflow:loss = 0.269023, step = 10001 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.262\n",
      "INFO:tensorflow:loss = 0.255944, step = 10101 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.675\n",
      "INFO:tensorflow:loss = 0.227741, step = 10201 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.147\n",
      "INFO:tensorflow:loss = 0.211503, step = 10301 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.807\n",
      "INFO:tensorflow:loss = 0.225175, step = 10401 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.234\n",
      "INFO:tensorflow:loss = 0.214592, step = 10501 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.734\n",
      "INFO:tensorflow:loss = 0.237488, step = 10601 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.674\n",
      "INFO:tensorflow:loss = 0.235904, step = 10701 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.673\n",
      "INFO:tensorflow:loss = 0.230506, step = 10801 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.881\n",
      "INFO:tensorflow:loss = 0.290159, step = 10901 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.239\n",
      "INFO:tensorflow:loss = 0.262993, step = 11001 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.808\n",
      "INFO:tensorflow:loss = 0.220026, step = 11101 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.047\n",
      "INFO:tensorflow:loss = 0.251631, step = 11201 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.673\n",
      "INFO:tensorflow:loss = 0.227221, step = 11301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.509\n",
      "INFO:tensorflow:loss = 0.217498, step = 11401 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.147\n",
      "INFO:tensorflow:loss = 0.221145, step = 11501 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.734\n",
      "INFO:tensorflow:loss = 0.227416, step = 11601 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.734\n",
      "INFO:tensorflow:loss = 0.211621, step = 11701 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.508\n",
      "INFO:tensorflow:loss = 0.259571, step = 11801 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.892\n",
      "INFO:tensorflow:loss = 0.246445, step = 11901 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.149\n",
      "INFO:tensorflow:loss = 0.249584, step = 12001 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.893\n",
      "INFO:tensorflow:loss = 0.19095, step = 12101 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.491\n",
      "INFO:tensorflow:loss = 0.268543, step = 12201 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.734\n",
      "INFO:tensorflow:loss = 0.247603, step = 12301 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.262\n",
      "INFO:tensorflow:loss = 0.24674, step = 12401 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.078\n",
      "INFO:tensorflow:loss = 0.229019, step = 12501 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.54\n",
      "INFO:tensorflow:loss = 0.208288, step = 12601 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.539\n",
      "INFO:tensorflow:loss = 0.214022, step = 12701 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.496\n",
      "INFO:tensorflow:loss = 0.219596, step = 12801 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.236\n",
      "INFO:tensorflow:loss = 0.235812, step = 12901 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.337\n",
      "INFO:tensorflow:loss = 0.225007, step = 13001 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.603\n",
      "INFO:tensorflow:loss = 0.20338, step = 13101 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.733\n",
      "INFO:tensorflow:loss = 0.247266, step = 13201 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.198\n",
      "INFO:tensorflow:loss = 0.234541, step = 13301 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.674\n",
      "INFO:tensorflow:loss = 0.203709, step = 13401 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.047\n",
      "INFO:tensorflow:loss = 0.223097, step = 13501 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.356\n",
      "INFO:tensorflow:loss = 0.21949, step = 13601 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.882\n",
      "INFO:tensorflow:loss = 0.208506, step = 13701 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.497\n",
      "INFO:tensorflow:loss = 0.216349, step = 13801 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.731\n",
      "INFO:tensorflow:loss = 0.233785, step = 13901 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.287\n",
      "INFO:tensorflow:loss = 0.242741, step = 14001 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.047\n",
      "INFO:tensorflow:loss = 0.237292, step = 14101 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.239\n",
      "INFO:tensorflow:loss = 0.245961, step = 14201 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.497\n",
      "INFO:tensorflow:loss = 0.22523, step = 14301 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.253\n",
      "INFO:tensorflow:loss = 0.232763, step = 14401 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.358\n",
      "INFO:tensorflow:loss = 0.216863, step = 14501 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.732\n",
      "INFO:tensorflow:loss = 0.232875, step = 14601 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.048\n",
      "INFO:tensorflow:loss = 0.232921, step = 14701 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.492\n",
      "INFO:tensorflow:loss = 0.253156, step = 14801 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.443\n",
      "INFO:tensorflow:loss = 0.255347, step = 14901 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.235\n",
      "INFO:tensorflow:loss = 0.231683, step = 15001 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.494\n",
      "INFO:tensorflow:loss = 0.208505, step = 15101 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.491\n",
      "INFO:tensorflow:loss = 0.224803, step = 15201 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.49\n",
      "INFO:tensorflow:loss = 0.234838, step = 15301 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.935\n",
      "INFO:tensorflow:loss = 0.202717, step = 15401 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.361\n",
      "INFO:tensorflow:loss = 0.2083, step = 15501 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.043\n",
      "INFO:tensorflow:loss = 0.216117, step = 15601 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.287\n",
      "INFO:tensorflow:loss = 0.236311, step = 15701 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.587\n",
      "INFO:tensorflow:loss = 0.212167, step = 15801 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.241\n",
      "INFO:tensorflow:loss = 0.255076, step = 15901 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.878\n",
      "INFO:tensorflow:loss = 0.259693, step = 16001 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.255\n",
      "INFO:tensorflow:loss = 0.223586, step = 16101 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:loss = 0.22551, step = 16201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.266\n",
      "INFO:tensorflow:loss = 0.227326, step = 16301 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.197\n",
      "INFO:tensorflow:loss = 0.286907, step = 16401 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.047\n",
      "INFO:tensorflow:loss = 0.246677, step = 16501 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.493\n",
      "INFO:tensorflow:loss = 0.258657, step = 16601 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.444\n",
      "INFO:tensorflow:loss = 0.214759, step = 16701 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.492\n",
      "INFO:tensorflow:loss = 0.236651, step = 16801 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.238\n",
      "INFO:tensorflow:loss = 0.273801, step = 16901 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.407\n",
      "INFO:tensorflow:loss = 0.203939, step = 17001 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.444\n",
      "INFO:tensorflow:loss = 0.242269, step = 17101 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.235\n",
      "INFO:tensorflow:loss = 0.245876, step = 17201 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.881\n",
      "INFO:tensorflow:loss = 0.224218, step = 17301 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.879\n",
      "INFO:tensorflow:loss = 0.240799, step = 17401 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.239\n",
      "INFO:tensorflow:loss = 0.239961, step = 17501 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.673\n",
      "INFO:tensorflow:loss = 0.217829, step = 17601 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.925\n",
      "INFO:tensorflow:loss = 0.264196, step = 17701 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.444\n",
      "INFO:tensorflow:loss = 0.220403, step = 17801 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.359\n",
      "INFO:tensorflow:loss = 0.253488, step = 17901 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.19\n",
      "INFO:tensorflow:loss = 0.205205, step = 18001 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.196\n",
      "INFO:tensorflow:loss = 0.257867, step = 18101 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.894\n",
      "INFO:tensorflow:loss = 0.214328, step = 18201 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.145\n",
      "INFO:tensorflow:loss = 0.212047, step = 18301 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.147\n",
      "INFO:tensorflow:loss = 0.240149, step = 18401 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.199\n",
      "INFO:tensorflow:loss = 0.215963, step = 18501 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.146\n",
      "INFO:tensorflow:loss = 0.22498, step = 18601 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.044\n",
      "INFO:tensorflow:loss = 0.22576, step = 18701 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.254\n",
      "INFO:tensorflow:loss = 0.236812, step = 18801 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.496\n",
      "INFO:tensorflow:loss = 0.259408, step = 18901 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.604\n",
      "INFO:tensorflow:loss = 0.232599, step = 19001 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.605\n",
      "INFO:tensorflow:loss = 0.275138, step = 19101 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.605\n",
      "INFO:tensorflow:loss = 0.246532, step = 19201 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.878\n",
      "INFO:tensorflow:loss = 0.222006, step = 19301 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.407\n",
      "INFO:tensorflow:loss = 0.236364, step = 19401 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.733\n",
      "INFO:tensorflow:loss = 0.278011, step = 19501 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.734\n",
      "INFO:tensorflow:loss = 0.22477, step = 19601 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.879\n",
      "INFO:tensorflow:loss = 0.243923, step = 19701 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.732\n",
      "INFO:tensorflow:loss = 0.22439, step = 19801 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.733\n",
      "INFO:tensorflow:loss = 0.226066, step = 19901 (0.217 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into C:\\Users\\AKHILE~1\\AppData\\Local\\Temp\\tmpbnls2qt9\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.21205.\n",
      "WARNING:tensorflow:From C:\\Users\\akhileshsk\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-05-13-17:11:58\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\AKHILE~1\\AppData\\Local\\Temp\\tmpbnls2qt9\\model.ckpt-20000\n",
      "INFO:tensorflow:Finished evaluation at 2017-05-13-17:11:59\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 0.231349\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "{'global_step': 20000, 'loss': 0.23134862}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "X = feature_mat\n",
    "y = labels\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.33, random_state=53)\n",
    "import tensorflow as tf\n",
    "# NumPy is often used to load, manipulate and preprocess data.\n",
    "import numpy as np\n",
    "\n",
    "# Declare list of features. We only have one real-valued feature. There are many\n",
    "# other types of columns that are more complicated and useful.\n",
    "features = [tf.contrib.layers.real_valued_column(\"x\", dimension=34)]\n",
    "\n",
    "# An estimator is the front end to invoke training (fitting) and evaluation\n",
    "# (inference). There are many predefined types like linear regression,\n",
    "# logistic regression, linear classification, logistic classification, and\n",
    "# many neural network classifiers and regressors. The following code\n",
    "# provides an estimator that does linear regression.\n",
    "estimator = tf.contrib.learn.DNNRegressor(feature_columns=features, hidden_units=[100,1000,1000,20],dropout = 0.6)\n",
    "\n",
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# Here we use `numpy_input_fn`. We have to tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be.\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":train_x}, train_y, batch_size=50,\n",
    "                                              num_epochs=20000)\n",
    "valid_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":valid_x[:10000]}, valid_y[:10000])\n",
    "\n",
    "test_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":valid_x[:50000]})\n",
    "\n",
    "# We can invoke 1000 training steps by invoking the `fit` method and passing the\n",
    "# training data set.\n",
    "estimator.fit(input_fn=input_fn, steps=20000)\n",
    "\n",
    "# Here we evaluate how well our model did. In a real example, we would want\n",
    "# to use a separate validation and testing data set to avoid overfitting.\n",
    "print(estimator.evaluate(input_fn=valid_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akhileshsk\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:335: calling DNNRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\AKHILE~1\\AppData\\Local\\Temp\\tmpi0m6dhyi\\model.ckpt-9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.68589219492346043"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":valid_x[:50000]})\n",
    "\n",
    "pred = list(estimator.predict(input_fn=test_fn))\n",
    "log_loss(valid_y[:50000],pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66958171360827978"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49679661,  0.27618706,  1.74137974,  0.38568139,  0.02343595,\n",
       "        1.99208403,  1.620543  ,  1.97830868,  0.00549448], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.pairwise.cosine_distances(q1_f_cos[0],q2_f_cos[0]).reshape(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = feature_mat\n",
    "y = labels\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.33, random_state=53)\n",
    "dtrain = xgb.DMatrix(train_x,label = train_y)\n",
    "dvalid = xgb.DMatrix(valid_x,label = valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.761521\ttrain-auc:0.854858\n",
      "[1]\teval-auc:0.774544\ttrain-auc:0.893015\n",
      "[2]\teval-auc:0.781399\ttrain-auc:0.91578\n",
      "[3]\teval-auc:0.786279\ttrain-auc:0.929804\n",
      "[4]\teval-auc:0.790435\ttrain-auc:0.941196\n",
      "[5]\teval-auc:0.793189\ttrain-auc:0.950622\n",
      "[6]\teval-auc:0.795956\ttrain-auc:0.957546\n",
      "[7]\teval-auc:0.79846\ttrain-auc:0.963027\n",
      "[8]\teval-auc:0.799678\ttrain-auc:0.967408\n",
      "[9]\teval-auc:0.80083\ttrain-auc:0.970392\n",
      "[10]\teval-auc:0.801898\ttrain-auc:0.973231\n",
      "[11]\teval-auc:0.803861\ttrain-auc:0.974988\n",
      "[12]\teval-auc:0.805067\ttrain-auc:0.976636\n",
      "[13]\teval-auc:0.805599\ttrain-auc:0.979293\n",
      "[14]\teval-auc:0.806366\ttrain-auc:0.98136\n",
      "[15]\teval-auc:0.80673\ttrain-auc:0.981939\n",
      "[16]\teval-auc:0.807313\ttrain-auc:0.983723\n",
      "[17]\teval-auc:0.807698\ttrain-auc:0.985519\n",
      "[18]\teval-auc:0.808073\ttrain-auc:0.987107\n",
      "[19]\teval-auc:0.808652\ttrain-auc:0.988162\n",
      "[20]\teval-auc:0.809191\ttrain-auc:0.989238\n",
      "[21]\teval-auc:0.809528\ttrain-auc:0.990121\n",
      "[22]\teval-auc:0.809977\ttrain-auc:0.991086\n",
      "[23]\teval-auc:0.809966\ttrain-auc:0.991848\n",
      "[24]\teval-auc:0.810151\ttrain-auc:0.992406\n",
      "[25]\teval-auc:0.810421\ttrain-auc:0.992865\n",
      "[26]\teval-auc:0.810563\ttrain-auc:0.993569\n",
      "[27]\teval-auc:0.810736\ttrain-auc:0.994166\n",
      "[28]\teval-auc:0.810873\ttrain-auc:0.994907\n",
      "[29]\teval-auc:0.810977\ttrain-auc:0.99541\n",
      "[30]\teval-auc:0.8112\ttrain-auc:0.995829\n",
      "[31]\teval-auc:0.811723\ttrain-auc:0.996259\n",
      "[32]\teval-auc:0.811577\ttrain-auc:0.996742\n",
      "[33]\teval-auc:0.81178\ttrain-auc:0.997107\n",
      "[34]\teval-auc:0.811942\ttrain-auc:0.99753\n",
      "[35]\teval-auc:0.81178\ttrain-auc:0.997836\n",
      "[36]\teval-auc:0.812153\ttrain-auc:0.998096\n",
      "[37]\teval-auc:0.812366\ttrain-auc:0.998336\n",
      "[38]\teval-auc:0.812265\ttrain-auc:0.998611\n",
      "[39]\teval-auc:0.812396\ttrain-auc:0.998816\n",
      "[40]\teval-auc:0.812537\ttrain-auc:0.998947\n",
      "[41]\teval-auc:0.812633\ttrain-auc:0.999118\n",
      "[42]\teval-auc:0.812836\ttrain-auc:0.999251\n",
      "[43]\teval-auc:0.812856\ttrain-auc:0.999384\n",
      "[44]\teval-auc:0.812837\ttrain-auc:0.999454\n",
      "[45]\teval-auc:0.812889\ttrain-auc:0.999538\n",
      "[46]\teval-auc:0.812998\ttrain-auc:0.9996\n",
      "[47]\teval-auc:0.812972\ttrain-auc:0.99966\n",
      "[48]\teval-auc:0.813147\ttrain-auc:0.999716\n",
      "[49]\teval-auc:0.813202\ttrain-auc:0.999749\n",
      "log loss 0.56280878614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "dtrain = xgb.DMatrix(train_x,label = train_y)\n",
    "dvalid = xgb.DMatrix(valid_x,label = valid_y)\n",
    "param = {'max_depth':25, 'eta':0.3, 'silent':0, 'objective':'binary:logistic','subsample':0.5,'gamma':0 }\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "#param['scale_pos_weight'] = ratio\n",
    "num_round = 50\n",
    "evallist  = [(dvalid,'eval'),(dtrain,'train')]\n",
    "bst = xgb.train( param, dtrain, num_round, evallist)\n",
    "loss = log_loss(valid_y,bst.predict(dvalid))\n",
    "print('log loss '+str(loss))\n",
    "#save model\n",
    "#bst.save_model('05_07_1AM.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test cases\n",
    "# putting together the test matrix\n",
    "b = pd.read_csv('E:/Dropbox/Kaggle_competitions/Quora competition/test.csv',delimiter = ',')\n",
    "b.ix[b['question1'].isnull(),['question1','question2']] = 'random empty question'\n",
    "b.ix[b['question2'].isnull(),['question1','question2']] = 'random empty question'\n",
    "q1 = b['question1'].values\n",
    "q2 = b['question2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.042629452859498436\n",
      "0.08525890571899687\n",
      "0.12788835857849531\n",
      "0.17051781143799374\n",
      "0.2131472642974922\n",
      "0.25577671715699063\n",
      "0.29840617001648906\n",
      "0.3410356228759875\n",
      "0.38366507573548597\n",
      "0.4262945285949844\n",
      "0.46892398145448283\n",
      "0.5115534343139813\n",
      "0.5541828871734797\n",
      "0.5968123400329781\n",
      "0.6394417928924766\n",
      "0.682071245751975\n",
      "0.7247006986114735\n",
      "0.7673301514709719\n",
      "0.8099596043304703\n",
      "0.8525890571899688\n",
      "0.8952185100494672\n",
      "0.9378479629089657\n",
      "0.9804774157684641\n",
      "0.0\n",
      "0.042629452859498436\n",
      "0.08525890571899687\n",
      "0.12788835857849531\n",
      "0.17051781143799374\n",
      "0.2131472642974922\n",
      "0.25577671715699063\n",
      "0.29840617001648906\n",
      "0.3410356228759875\n",
      "0.38366507573548597\n",
      "0.4262945285949844\n",
      "0.46892398145448283\n",
      "0.5115534343139813\n",
      "0.5541828871734797\n",
      "0.5968123400329781\n",
      "0.6394417928924766\n",
      "0.682071245751975\n",
      "0.7247006986114735\n",
      "0.7673301514709719\n",
      "0.8099596043304703\n",
      "0.8525890571899688\n",
      "0.8952185100494672\n",
      "0.9378479629089657\n",
      "0.9804774157684641\n"
     ]
    }
   ],
   "source": [
    "del question1_data\n",
    "del question2_data\n",
    "#checki if words are in dictionary first\n",
    "question1_data = []\n",
    "question2_data = []\n",
    "count = 0\n",
    "for j in range(len(q1)):\n",
    "    if j%100000==0:\n",
    "        print(j/(len(q1)))\n",
    "    auto_data = []\n",
    "    line = q1[j]    \n",
    "    temp_words = ''.join( c for c in line if  c not in specialstr ).split()\n",
    "    #adding the leaves\n",
    "    #print(count)\n",
    "    for i in temp_words:\n",
    "        auto_data.append(final_embeddings[dictionary[get_word(i.lower())]])\n",
    "    auto_data = np.array(auto_data)\n",
    "    question1_data.append(auto_data)\n",
    "    count+=1\n",
    "    \n",
    "question1_data =  np.array(question1_data)\n",
    "\n",
    "for j in range(len(q2)):\n",
    "    if j%100000==0:\n",
    "        print(j/(len(q1)))\n",
    "    auto_data = []\n",
    "    line = q2[j]    \n",
    "    temp_words = ''.join( c for c in line if  c not in specialstr ).split()\n",
    "    #adding the leaves\n",
    "    for i in temp_words:\n",
    "        auto_data.append(final_embeddings[dictionary[get_word(i.lower())]])\n",
    "    #parent_q2.append([auto_data,j])\n",
    "    auto_data = np.array(auto_data)\n",
    "    question2_data.append(auto_data)\n",
    "    \n",
    "question2_data =  np.array(question2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = []\n",
    "for i in range(len(question1_data)):\n",
    "    if question1_data[i].shape[0]==0 or question2_data[i].shape[0]==0 or question1_data[i].shape[0]==1 or question2_data[i].shape[0]==1 or question1_data[i].shape[0]==2 or question2_data[i].shape[0]==2:\n",
    "        pos.append(i)\n",
    "question1_data = np.delete(question1_data,pos)\n",
    "question2_data = np.delete(question2_data,pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[89,\n",
       " 122,\n",
       " 229,\n",
       " 317,\n",
       " 330,\n",
       " 355,\n",
       " 381,\n",
       " 520,\n",
       " 532,\n",
       " 856,\n",
       " 895,\n",
       " 975,\n",
       " 1138,\n",
       " 1186,\n",
       " 1249,\n",
       " 1263,\n",
       " 1284,\n",
       " 1341,\n",
       " 1345,\n",
       " 1425,\n",
       " 1442,\n",
       " 1454,\n",
       " 1500,\n",
       " 1504,\n",
       " 1535,\n",
       " 1551,\n",
       " 1597,\n",
       " 1632,\n",
       " 1708,\n",
       " 1743,\n",
       " 1951,\n",
       " 1954,\n",
       " 1986,\n",
       " 2006,\n",
       " 2086,\n",
       " 2130,\n",
       " 2133,\n",
       " 2558,\n",
       " 2704,\n",
       " 2721,\n",
       " 2736,\n",
       " 2747,\n",
       " 2838,\n",
       " 2934,\n",
       " 2984,\n",
       " 3065,\n",
       " 3110,\n",
       " 3182,\n",
       " 3242,\n",
       " 3422,\n",
       " 3472,\n",
       " 3491,\n",
       " 3502,\n",
       " 3574,\n",
       " 3612,\n",
       " 3774,\n",
       " 3864,\n",
       " 4150,\n",
       " 4254,\n",
       " 4315,\n",
       " 4357,\n",
       " 4482,\n",
       " 4490,\n",
       " 4535,\n",
       " 4543,\n",
       " 4690,\n",
       " 4691,\n",
       " 4854,\n",
       " 4877,\n",
       " 4897,\n",
       " 4906,\n",
       " 4922,\n",
       " 4953,\n",
       " 4971,\n",
       " 5084,\n",
       " 5130,\n",
       " 5177,\n",
       " 5193,\n",
       " 5300,\n",
       " 5472,\n",
       " 5502,\n",
       " 5574,\n",
       " 5613,\n",
       " 5797,\n",
       " 5819,\n",
       " 5822,\n",
       " 5853,\n",
       " 5968,\n",
       " 6050,\n",
       " 6084,\n",
       " 6212,\n",
       " 6220,\n",
       " 6273,\n",
       " 6298,\n",
       " 6401,\n",
       " 6550,\n",
       " 6635,\n",
       " 6668,\n",
       " 6685,\n",
       " 6692,\n",
       " 6751,\n",
       " 6758,\n",
       " 6850,\n",
       " 6964,\n",
       " 7116,\n",
       " 7177,\n",
       " 7264,\n",
       " 7269,\n",
       " 7305,\n",
       " 7307,\n",
       " 7348,\n",
       " 7509,\n",
       " 7520,\n",
       " 7662,\n",
       " 7664,\n",
       " 7724,\n",
       " 7903,\n",
       " 7988,\n",
       " 8008,\n",
       " 8020,\n",
       " 8068,\n",
       " 8090,\n",
       " 8095,\n",
       " 8268,\n",
       " 8272,\n",
       " 8363,\n",
       " 8364,\n",
       " 8403,\n",
       " 8546,\n",
       " 8597,\n",
       " 8787,\n",
       " 8935,\n",
       " 9077,\n",
       " 9143,\n",
       " 9233,\n",
       " 9253,\n",
       " 9264,\n",
       " 9319,\n",
       " 9496,\n",
       " 9701,\n",
       " 9761,\n",
       " 9862,\n",
       " 9975,\n",
       " 10053,\n",
       " 10105,\n",
       " 10148,\n",
       " 10187,\n",
       " 10367,\n",
       " 10391,\n",
       " 10408,\n",
       " 10433,\n",
       " 10445,\n",
       " 10505,\n",
       " 10629,\n",
       " 10646,\n",
       " 10656,\n",
       " 10717,\n",
       " 10830,\n",
       " 10861,\n",
       " 10883,\n",
       " 11070,\n",
       " 11283,\n",
       " 11456,\n",
       " 11487,\n",
       " 11603,\n",
       " 11724,\n",
       " 11770,\n",
       " 11806,\n",
       " 11880,\n",
       " 11893,\n",
       " 11964,\n",
       " 12048,\n",
       " 12054,\n",
       " 12095,\n",
       " 12158,\n",
       " 12196,\n",
       " 12251,\n",
       " 12282,\n",
       " 12427,\n",
       " 12620,\n",
       " 12707,\n",
       " 12714,\n",
       " 12791,\n",
       " 12872,\n",
       " 13060,\n",
       " 13320,\n",
       " 13398,\n",
       " 13426,\n",
       " 13742,\n",
       " 13781,\n",
       " 13849,\n",
       " 13866,\n",
       " 13900,\n",
       " 13916,\n",
       " 14010,\n",
       " 14011,\n",
       " 14046,\n",
       " 14244,\n",
       " 14335,\n",
       " 14449,\n",
       " 14474,\n",
       " 14475,\n",
       " 14550,\n",
       " 14627,\n",
       " 14694,\n",
       " 14760,\n",
       " 14802,\n",
       " 14803,\n",
       " 14829,\n",
       " 14986,\n",
       " 15022,\n",
       " 15027,\n",
       " 15240,\n",
       " 15366,\n",
       " 15420,\n",
       " 15450,\n",
       " 15464,\n",
       " 15661,\n",
       " 15704,\n",
       " 15796,\n",
       " 15819,\n",
       " 15885,\n",
       " 15954,\n",
       " 16023,\n",
       " 16030,\n",
       " 16062,\n",
       " 16108,\n",
       " 16191,\n",
       " 16264,\n",
       " 16267,\n",
       " 16310,\n",
       " 16364,\n",
       " 16392,\n",
       " 16396,\n",
       " 16443,\n",
       " 16482,\n",
       " 16530,\n",
       " 16584,\n",
       " 16586,\n",
       " 16624,\n",
       " 16630,\n",
       " 16684,\n",
       " 16836,\n",
       " 17021,\n",
       " 17152,\n",
       " 17154,\n",
       " 17187,\n",
       " 17194,\n",
       " 17197,\n",
       " 17292,\n",
       " 17311,\n",
       " 17423,\n",
       " 17466,\n",
       " 17495,\n",
       " 17568,\n",
       " 17684,\n",
       " 17730,\n",
       " 17828,\n",
       " 17863,\n",
       " 17928,\n",
       " 17936,\n",
       " 17993,\n",
       " 18031,\n",
       " 18230,\n",
       " 18244,\n",
       " 18251,\n",
       " 18317,\n",
       " 18384,\n",
       " 18475,\n",
       " 18578,\n",
       " 18612,\n",
       " 18780,\n",
       " 18793,\n",
       " 18795,\n",
       " 18797,\n",
       " 18807,\n",
       " 18842,\n",
       " 18844,\n",
       " 18905,\n",
       " 18979,\n",
       " 18991,\n",
       " 18999,\n",
       " 19047,\n",
       " 19056,\n",
       " 19069,\n",
       " 19106,\n",
       " 19162,\n",
       " 19261,\n",
       " 19312,\n",
       " 19365,\n",
       " 19378,\n",
       " 19382,\n",
       " 19408,\n",
       " 19418,\n",
       " 19523,\n",
       " 19543,\n",
       " 19712,\n",
       " 19878,\n",
       " 19904,\n",
       " 19909,\n",
       " 19964,\n",
       " 20013,\n",
       " 20085,\n",
       " 20175,\n",
       " 20184,\n",
       " 20285,\n",
       " 20397,\n",
       " 20528,\n",
       " 20541,\n",
       " 20544,\n",
       " 20550,\n",
       " 20668,\n",
       " 20714,\n",
       " 20746,\n",
       " 20962,\n",
       " 21120,\n",
       " 21163,\n",
       " 21470,\n",
       " 21509,\n",
       " 21556,\n",
       " 21645,\n",
       " 21782,\n",
       " 21808,\n",
       " 21881,\n",
       " 21971,\n",
       " 21990,\n",
       " 21994,\n",
       " 22175,\n",
       " 22214,\n",
       " 22362,\n",
       " 22424,\n",
       " 22630,\n",
       " 22638,\n",
       " 22642,\n",
       " 22680,\n",
       " 22713,\n",
       " 22725,\n",
       " 22834,\n",
       " 23054,\n",
       " 23065,\n",
       " 23086,\n",
       " 23121,\n",
       " 23147,\n",
       " 23150,\n",
       " 23169,\n",
       " 23367,\n",
       " 23376,\n",
       " 23503,\n",
       " 23572,\n",
       " 23964,\n",
       " 24152,\n",
       " 24200,\n",
       " 24232,\n",
       " 24260,\n",
       " 24442,\n",
       " 24461,\n",
       " 24492,\n",
       " 24656,\n",
       " 24674,\n",
       " 24724,\n",
       " 24750,\n",
       " 24933,\n",
       " 25000,\n",
       " 25018,\n",
       " 25042,\n",
       " 25098,\n",
       " 25148,\n",
       " 25202,\n",
       " 25228,\n",
       " 25347,\n",
       " 25450,\n",
       " 25470,\n",
       " 25556,\n",
       " 25632,\n",
       " 25646,\n",
       " 25666,\n",
       " 25682,\n",
       " 25717,\n",
       " 25730,\n",
       " 25881,\n",
       " 25982,\n",
       " 26116,\n",
       " 26139,\n",
       " 26143,\n",
       " 26202,\n",
       " 26230,\n",
       " 26247,\n",
       " 26307,\n",
       " 26320,\n",
       " 26366,\n",
       " 26368,\n",
       " 26467,\n",
       " 26497,\n",
       " 26501,\n",
       " 26611,\n",
       " 26706,\n",
       " 26752,\n",
       " 26827,\n",
       " 26863,\n",
       " 26904,\n",
       " 26967,\n",
       " 26996,\n",
       " 27009,\n",
       " 27098,\n",
       " 27250,\n",
       " 27339,\n",
       " 27393,\n",
       " 27398,\n",
       " 27416,\n",
       " 27500,\n",
       " 27658,\n",
       " 27668,\n",
       " 27709,\n",
       " 27753,\n",
       " 27805,\n",
       " 27937,\n",
       " 28054,\n",
       " 28076,\n",
       " 28305,\n",
       " 28489,\n",
       " 28515,\n",
       " 28559,\n",
       " 28649,\n",
       " 28778,\n",
       " 28909,\n",
       " 28919,\n",
       " 28945,\n",
       " 28962,\n",
       " 29029,\n",
       " 29039,\n",
       " 29097,\n",
       " 29173,\n",
       " 29192,\n",
       " 29232,\n",
       " 29252,\n",
       " 29323,\n",
       " 29347,\n",
       " 29388,\n",
       " 29433,\n",
       " 29553,\n",
       " 29638,\n",
       " 29704,\n",
       " 29728,\n",
       " 29736,\n",
       " 29743,\n",
       " 29815,\n",
       " 29823,\n",
       " 29830,\n",
       " 29855,\n",
       " 29875,\n",
       " 29881,\n",
       " 29944,\n",
       " 30045,\n",
       " 30051,\n",
       " 30098,\n",
       " 30243,\n",
       " 30285,\n",
       " 30350,\n",
       " 30403,\n",
       " 30420,\n",
       " 30512,\n",
       " 30532,\n",
       " 30616,\n",
       " 30635,\n",
       " 30657,\n",
       " 30664,\n",
       " 30738,\n",
       " 30767,\n",
       " 30829,\n",
       " 30878,\n",
       " 30994,\n",
       " 31036,\n",
       " 31204,\n",
       " 31208,\n",
       " 31286,\n",
       " 31302,\n",
       " 31339,\n",
       " 31376,\n",
       " 31429,\n",
       " 31433,\n",
       " 31456,\n",
       " 31515,\n",
       " 31539,\n",
       " 31584,\n",
       " 31610,\n",
       " 31730,\n",
       " 31742,\n",
       " 31775,\n",
       " 31845,\n",
       " 31985,\n",
       " 31991,\n",
       " 32067,\n",
       " 32069,\n",
       " 32080,\n",
       " 32100,\n",
       " 32243,\n",
       " 32259,\n",
       " 32273,\n",
       " 32290,\n",
       " 32365,\n",
       " 32394,\n",
       " 32411,\n",
       " 32430,\n",
       " 32484,\n",
       " 32491,\n",
       " 32506,\n",
       " 32625,\n",
       " 32739,\n",
       " 32763,\n",
       " 32791,\n",
       " 32807,\n",
       " 32830,\n",
       " 32968,\n",
       " 33006,\n",
       " 33224,\n",
       " 33444,\n",
       " 33465,\n",
       " 33468,\n",
       " 33592,\n",
       " 33608,\n",
       " 33628,\n",
       " 33682,\n",
       " 33771,\n",
       " 33829,\n",
       " 33836,\n",
       " 33910,\n",
       " 33911,\n",
       " 33926,\n",
       " 33981,\n",
       " 33991,\n",
       " 33995,\n",
       " 34023,\n",
       " 34048,\n",
       " 34237,\n",
       " 34302,\n",
       " 34311,\n",
       " 34356,\n",
       " 34498,\n",
       " 34554,\n",
       " 34748,\n",
       " 34828,\n",
       " 34837,\n",
       " 35084,\n",
       " 35184,\n",
       " 35193,\n",
       " 35245,\n",
       " 35295,\n",
       " 35296,\n",
       " 35339,\n",
       " 35368,\n",
       " 35440,\n",
       " 35497,\n",
       " 35498,\n",
       " 35560,\n",
       " 35798,\n",
       " 35835,\n",
       " 35938,\n",
       " 35939,\n",
       " 35995,\n",
       " 36008,\n",
       " 36019,\n",
       " 36136,\n",
       " 36200,\n",
       " 36213,\n",
       " 36235,\n",
       " 36256,\n",
       " 36378,\n",
       " 36393,\n",
       " 36472,\n",
       " 36508,\n",
       " 36640,\n",
       " 36691,\n",
       " 36724,\n",
       " 36750,\n",
       " 36842,\n",
       " 36860,\n",
       " 36874,\n",
       " 36944,\n",
       " 36956,\n",
       " 36973,\n",
       " 37085,\n",
       " 37095,\n",
       " 37376,\n",
       " 37515,\n",
       " 37624,\n",
       " 37679,\n",
       " 37709,\n",
       " 37770,\n",
       " 37778,\n",
       " 37823,\n",
       " 37841,\n",
       " 37984,\n",
       " 38003,\n",
       " 38005,\n",
       " 38122,\n",
       " 38188,\n",
       " 38222,\n",
       " 38301,\n",
       " 38308,\n",
       " 38476,\n",
       " 38610,\n",
       " 38617,\n",
       " 38683,\n",
       " 38690,\n",
       " 38725,\n",
       " 38769,\n",
       " 38807,\n",
       " 38910,\n",
       " 38914,\n",
       " 38964,\n",
       " 39031,\n",
       " 39068,\n",
       " 39103,\n",
       " 39161,\n",
       " 39242,\n",
       " 39274,\n",
       " 39363,\n",
       " 39416,\n",
       " 39424,\n",
       " 39431,\n",
       " 39444,\n",
       " 39563,\n",
       " 39576,\n",
       " 39647,\n",
       " 39770,\n",
       " 39830,\n",
       " 39848,\n",
       " 39857,\n",
       " 39866,\n",
       " 39886,\n",
       " 39981,\n",
       " 40021,\n",
       " 40054,\n",
       " 40067,\n",
       " 40385,\n",
       " 40526,\n",
       " 40708,\n",
       " 40749,\n",
       " 40764,\n",
       " 40820,\n",
       " 40845,\n",
       " 40884,\n",
       " 40910,\n",
       " 41105,\n",
       " 41200,\n",
       " 41206,\n",
       " 41258,\n",
       " 41282,\n",
       " 41454,\n",
       " 41472,\n",
       " 41584,\n",
       " 41595,\n",
       " 41623,\n",
       " 41716,\n",
       " 41751,\n",
       " 41850,\n",
       " 42041,\n",
       " 42056,\n",
       " 42057,\n",
       " 42275,\n",
       " 42309,\n",
       " 42346,\n",
       " 42359,\n",
       " 42454,\n",
       " 42467,\n",
       " 42472,\n",
       " 42476,\n",
       " 42826,\n",
       " 42837,\n",
       " 42907,\n",
       " 42978,\n",
       " 42981,\n",
       " 43119,\n",
       " 43229,\n",
       " 43230,\n",
       " 43396,\n",
       " 43407,\n",
       " 43410,\n",
       " 43423,\n",
       " 43487,\n",
       " 43641,\n",
       " 43704,\n",
       " 43705,\n",
       " 43747,\n",
       " 43763,\n",
       " 43792,\n",
       " 43865,\n",
       " 43880,\n",
       " 44020,\n",
       " 44031,\n",
       " 44194,\n",
       " 44198,\n",
       " 44243,\n",
       " 44248,\n",
       " 44452,\n",
       " 44948,\n",
       " 44966,\n",
       " 44976,\n",
       " 44997,\n",
       " 45020,\n",
       " 45029,\n",
       " 45045,\n",
       " 45050,\n",
       " 45134,\n",
       " 45347,\n",
       " 45515,\n",
       " 45520,\n",
       " 45570,\n",
       " 45593,\n",
       " 45636,\n",
       " 45693,\n",
       " 45727,\n",
       " 45765,\n",
       " 45815,\n",
       " 45836,\n",
       " 45892,\n",
       " 45902,\n",
       " 45924,\n",
       " 45933,\n",
       " 45965,\n",
       " 46050,\n",
       " 46068,\n",
       " 46099,\n",
       " 46150,\n",
       " 46227,\n",
       " 46257,\n",
       " 46275,\n",
       " 46309,\n",
       " 46624,\n",
       " 46662,\n",
       " 46698,\n",
       " 46813,\n",
       " 46823,\n",
       " 46855,\n",
       " 46969,\n",
       " 47015,\n",
       " 47026,\n",
       " 47028,\n",
       " 47038,\n",
       " 47123,\n",
       " 47134,\n",
       " 47139,\n",
       " 47154,\n",
       " 47182,\n",
       " 47225,\n",
       " 47248,\n",
       " 47303,\n",
       " 47312,\n",
       " 47324,\n",
       " 47349,\n",
       " 47543,\n",
       " 47695,\n",
       " 47707,\n",
       " 47797,\n",
       " 47844,\n",
       " 47881,\n",
       " 47957,\n",
       " 48016,\n",
       " 48165,\n",
       " 48213,\n",
       " 48238,\n",
       " 48249,\n",
       " 48250,\n",
       " 48261,\n",
       " 48278,\n",
       " 48562,\n",
       " 48594,\n",
       " 48752,\n",
       " 48755,\n",
       " 48784,\n",
       " 48869,\n",
       " 49042,\n",
       " 49059,\n",
       " 49212,\n",
       " 49344,\n",
       " 49389,\n",
       " 49497,\n",
       " 49564,\n",
       " 49569,\n",
       " 49590,\n",
       " 49601,\n",
       " 49870,\n",
       " 50073,\n",
       " 50111,\n",
       " 50118,\n",
       " 50179,\n",
       " 50187,\n",
       " 50407,\n",
       " 50542,\n",
       " 50590,\n",
       " 50611,\n",
       " 50661,\n",
       " 50797,\n",
       " 50815,\n",
       " 50990,\n",
       " 51016,\n",
       " 51132,\n",
       " 51156,\n",
       " 51173,\n",
       " 51205,\n",
       " 51245,\n",
       " 51360,\n",
       " 51408,\n",
       " 51462,\n",
       " 51545,\n",
       " 51575,\n",
       " 51632,\n",
       " 51727,\n",
       " 51754,\n",
       " 51782,\n",
       " 51851,\n",
       " 51962,\n",
       " 52018,\n",
       " 52179,\n",
       " 52212,\n",
       " 52278,\n",
       " 52313,\n",
       " 52406,\n",
       " 52416,\n",
       " 52632,\n",
       " 52674,\n",
       " 52800,\n",
       " 52981,\n",
       " 52989,\n",
       " 53010,\n",
       " 53080,\n",
       " 53100,\n",
       " 53123,\n",
       " 53178,\n",
       " 53213,\n",
       " 53233,\n",
       " 53270,\n",
       " 53303,\n",
       " 53342,\n",
       " 53487,\n",
       " 53509,\n",
       " 53532,\n",
       " 53548,\n",
       " 53665,\n",
       " 53686,\n",
       " 53777,\n",
       " 53845,\n",
       " 53900,\n",
       " 53946,\n",
       " 54092,\n",
       " 54280,\n",
       " 54292,\n",
       " 54293,\n",
       " 54331,\n",
       " 54551,\n",
       " 54680,\n",
       " 54777,\n",
       " 54787,\n",
       " 54824,\n",
       " 54901,\n",
       " 54917,\n",
       " 54951,\n",
       " 55039,\n",
       " 55144,\n",
       " 55240,\n",
       " 55281,\n",
       " 55383,\n",
       " 55468,\n",
       " 55472,\n",
       " 55540,\n",
       " 55605,\n",
       " 55701,\n",
       " 55709,\n",
       " 55959,\n",
       " 55993,\n",
       " 56050,\n",
       " 56065,\n",
       " 56113,\n",
       " 56143,\n",
       " 56173,\n",
       " 56193,\n",
       " 56427,\n",
       " 56436,\n",
       " 56474,\n",
       " 56511,\n",
       " 56586,\n",
       " 56602,\n",
       " 56635,\n",
       " 56648,\n",
       " 56761,\n",
       " 56764,\n",
       " 56929,\n",
       " 56983,\n",
       " 57086,\n",
       " 57104,\n",
       " 57182,\n",
       " 57227,\n",
       " 57229,\n",
       " 57310,\n",
       " 57524,\n",
       " 57636,\n",
       " 57649,\n",
       " 57721,\n",
       " 57767,\n",
       " 57807,\n",
       " 57840,\n",
       " 57951,\n",
       " 58054,\n",
       " 58078,\n",
       " 58080,\n",
       " 58096,\n",
       " 58132,\n",
       " 58142,\n",
       " 58176,\n",
       " 58231,\n",
       " 58238,\n",
       " 58269,\n",
       " 58287,\n",
       " 58394,\n",
       " 58489,\n",
       " 58572,\n",
       " 58608,\n",
       " 58655,\n",
       " 58721,\n",
       " 58752,\n",
       " 59024,\n",
       " 59188,\n",
       " 59442,\n",
       " 59482,\n",
       " 59663,\n",
       " 59703,\n",
       " 59741,\n",
       " 59779,\n",
       " 59798,\n",
       " 59817,\n",
       " 59863,\n",
       " 59867,\n",
       " 59888,\n",
       " 60098,\n",
       " 60119,\n",
       " 60266,\n",
       " 60277,\n",
       " 60284,\n",
       " 60374,\n",
       " 60417,\n",
       " 60457,\n",
       " 60552,\n",
       " 60762,\n",
       " 60781,\n",
       " 60784,\n",
       " 60786,\n",
       " 60946,\n",
       " 61011,\n",
       " 61124,\n",
       " 61190,\n",
       " 61207,\n",
       " 61346,\n",
       " 61383,\n",
       " 61595,\n",
       " 61698,\n",
       " 61808,\n",
       " 61980,\n",
       " 62066,\n",
       " 62118,\n",
       " 62152,\n",
       " 62235,\n",
       " 62236,\n",
       " 62333,\n",
       " 62347,\n",
       " 62496,\n",
       " 62657,\n",
       " 62736,\n",
       " 62803,\n",
       " 62832,\n",
       " 62860,\n",
       " 62979,\n",
       " 62983,\n",
       " 62984,\n",
       " 63066,\n",
       " 63129,\n",
       " 63158,\n",
       " 63186,\n",
       " 63358,\n",
       " 63363,\n",
       " 63408,\n",
       " 63430,\n",
       " 63515,\n",
       " 63517,\n",
       " 63715,\n",
       " 63727,\n",
       " 63823,\n",
       " 63826,\n",
       " 64041,\n",
       " 64167,\n",
       " 64198,\n",
       " 64206,\n",
       " 64277,\n",
       " 64293,\n",
       " 64299,\n",
       " 64363,\n",
       " 64433,\n",
       " 64483,\n",
       " 64515,\n",
       " 64587,\n",
       " 64606,\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n"
     ]
    }
   ],
   "source": [
    "#q1_f = np.ones((len(question1_data),3,128),np.float32)\n",
    "q1_f_cos =np.ones((len(question1_data),3,128),np.float32) \n",
    "q1_f_plane = np.ones((len(question1_data),5,128),np.float32)\n",
    "for i in range(question1_data.shape[0]):\n",
    "    if i%100000==0:\n",
    "        print(i)\n",
    "    f1 = np.sum(question1_data[i],0)\n",
    "    f2 = np.sum(question1_data[i][:-1],0)\n",
    "    f3 = question1_data[i][-1]\n",
    "    f4 = np.sum(question1_data[i][1:],0)\n",
    "    f5 = question1_data[i][0]\n",
    "    #q1_f[i] = [f1,f2,f3]\n",
    "    q1_f_cos[i] = [f1-f2,f2-f3,f3-f1]\n",
    "    q1_f_plane[i] = [f1,f2,f3,f4,f5]\n",
    "\n",
    "#q2_f = np.ones((len(question2_data),3,128),np.float32)\n",
    "q2_f_cos =np.ones((len(question1_data),3,128),np.float32)\n",
    "q2_f_plane = np.ones((len(question1_data),5,128),np.float32)\n",
    "for i in range(question1_data.shape[0]):\n",
    "    if i%100000==0:\n",
    "        print(i)\n",
    "    f1 = np.sum(question2_data[i],0)\n",
    "    f2 = np.sum(question2_data[i][:-1],0)\n",
    "    f3 = question2_data[i][-1]\n",
    "    f4 = np.sum(question2_data[i][1:],0)\n",
    "    f5 = question2_data[i][0]\n",
    "    #q2_f[i] = [f1,f2,f3]\n",
    "    q2_f_cos[i] = [f1-f2,f2-f3,f3-f1]\n",
    "    q2_f_plane[i] = [f1,f2,f3,f4,f5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "dist = np.ones((len(q1_f_plane),25),np.float32)\n",
    "dist_cos = np.ones((len(q1_f_plane),9),np.float32)\n",
    "for i in range(len(q1_f_plane)):\n",
    "    dist[i] = sklearn.metrics.pairwise.pairwise_distances(q1_f_plane[i],q2_f_plane[i]).reshape(25)\n",
    "    dist_cos[i] = sklearn.metrics.pairwise.cosine_distances(q1_f_cos[i],q2_f_cos[i]).reshape(9)\n",
    "feature_mat = np.hstack((dist,dist_cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "position = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(feature_mat)\n",
    "results = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21163708,  0.1247504 ,  0.73167419, ...,  0.00122685,\n",
       "        0.19946383,  0.21126997], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_inds = np.setdiff1d(np.arange(b.shape[0]),pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = np.zeros(b.shape[0],np.float32)\n",
    "result2[diff_inds] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% create a submission\n",
    "\n",
    "submissionName = 'word_2vec_vectors_xgb'\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['test_id'] = b['test_id']\n",
    "submission['is_duplicate'] = result2\n",
    "submission.to_csv(submissionName + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Why did Microsoft choose core m3 and not core i3 home Surface Pro 4?',\n",
       "       'How much cost does hair transplant require?',\n",
       "       'What you send money to China?', ...,\n",
       "       'Can a non-alcoholic restaurant be a huge success?',\n",
       "       'What are the best and worst things examination public transit in Visakhapatnam, Andhra Pradesh, India? How could it be improved?',\n",
       "       'How do I out get rid of Erectile Dysfunction?'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['How does the Surface Pro himself 4 compare with iPad Pro?',\n",
       "       'Should I have a hair transplant at age 24? How much would it cost?',\n",
       "       'What but is the best way to send money from China to the US?', ...,\n",
       "       'What are some famous Romanian drinks (alcoholic & non-alcoholic)?',\n",
       "       'What were the best and worst things about public transit in Proddatur, Andhra Pradesh, India? How could it be improved?',\n",
       "       'What is the best medication equation erectile dysfunction?'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
